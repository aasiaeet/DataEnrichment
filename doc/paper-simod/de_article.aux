\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{candes2010power}
\citation{donoho2006compressed}
\citation{friedman2008sparse}
\citation{candes2009exact}
\citation{candes2006robust}
\citation{tibshirani1996regression}
\citation{bach2012optimization}
\citation{negahban2009unified}
\citation{boufounos20081}
\citation{plan2017high}
\citation{blumensath2009iterative}
\citation{jain2013low}
\citation{barretina2012cancer}
\citation{iorio2016landscape1}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\citation{guba16}
\citation{mctr13}
\citation{Yang2013-pf}
\citation{jrsr10}
\citation{Zhang2017-rm}
\citation{grti16}
\citation{asiaee2018high}
\citation{asiaeedata}
\citation{Chen2015-fj}
\citation{domu16}
\citation{grti16}
\citation{olvi14}
\citation{olvi15}
\citation{Kakade2010-st}
\citation{negahban2012restricted}
\citation{Plan2013-nx}
\citation{Plan2016-de}
\citation{Yang2016-zd}
\citation{Zhang2017-rm}
\citation{Chen2012-fb}
\citation{jrsr10}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces A conceptual illustration of data sharing model for learning representation of cat species. The common parameter $\bm  {\beta }_0$ captures a \emph  {generic cat} which consists of shared features among all cats.\relax }}{2}{figure.caption.3}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:cat}{{1}{2}{A conceptual illustration of data sharing model for learning representation of cat species. The common parameter $\bbeta _0$ captures a \emph {generic cat} which consists of shared features among all cats.\relax }{figure.caption.3}{}}
\newlabel{fig:cat@cref}{{[figure][1][]1}{[1][2][]2}}
\newlabel{eq:dsl}{{1.1}{2}{Introduction}{equation.2}{}}
\newlabel{eq:dsl@cref}{{[equation][1][1]1.1}{[1][2][]2}}
\@writefile{toc}{\contentsline {paragraph}{The setting}{2}{section*.4}\protected@file@percent }
\citation{jrsr10}
\citation{domu16}
\citation{grti16}
\citation{olvi15}
\citation{olvi14}
\citation{domu16}
\citation{grti16}
\citation{olvi14}
\citation{olvi15}
\citation{olvi15}
\citation{jrsr10}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Related Work}{3}{subsection.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Motivation}{3}{section*.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Notation and Preliminaries}{3}{subsection.7}\protected@file@percent }
\newlabel{eq:dirtymodel}{{1.2}{3}{Notation and Preliminaries}{equation.8}{}}
\newlabel{eq:dirtymodel@cref}{{[equation][2][1]1.2}{[1][3][]3}}
\citation{vers12}
\citation{vers12}
\citation{vershynin2018high}
\citation{guba16}
\citation{mctr13}
\citation{guba16}
\citation{guba16}
\@writefile{toc}{\contentsline {paragraph}{Sub-Gaussian random variable and vector}{4}{section*.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Our Contributions}{4}{subsection.10}\protected@file@percent }
\newlabel{eq:super}{{1.3}{4}{Our Contributions}{equation.11}{}}
\newlabel{eq:super@cref}{{[equation][3][1]1.3}{[1][4][]4}}
\newlabel{eq:errorsum}{{1.4}{4}{Our Contributions}{equation.12}{}}
\newlabel{eq:errorsum@cref}{{[equation][4][1]1.4}{[1][4][]4}}
\newlabel{fig:sc}{{2a}{5}{Structural Coherence (SC) condition.\relax }{figure.caption.13}{}}
\newlabel{fig:sc@cref}{{[subfigure][1][2]2a}{[1][4][]5}}
\newlabel{sub@fig:sc}{{a}{5}{Structural Coherence (SC) condition.\relax }{figure.caption.13}{}}
\newlabel{sub@fig:sc@cref}{{[subfigure][1][2]2a}{[1][4][]5}}
\newlabel{fig:DASHIN}{{2b}{5}{DAta SHaring Incoherence conditioN (\ds ).\relax }{figure.caption.13}{}}
\newlabel{fig:DASHIN@cref}{{[subfigure][2][2]2b}{[1][4][]5}}
\newlabel{sub@fig:DASHIN}{{b}{5}{DAta SHaring Incoherence conditioN (\ds ).\relax }{figure.caption.13}{}}
\newlabel{sub@fig:DASHIN@cref}{{[subfigure][2][2]2b}{[1][4][]5}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Comparison of geometric recovery condition for superposition models known as Structural Coherence (SC) \cite  {guba16} and our {\sc  Dashin}\ recovery condition for data sharing model which is a system of coupled superposition models \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces \ref  {eq:dirtymodel}\unskip \@@italiccorr )}}. For each parameter $\bm  {\beta }^*_g \in [G]$, ${\cal  E}_g = \left \{\bm  {\delta }_g | f_g(\bm  {\beta }_g^* + \bm  {\delta }_g) \leq f_g(\bm  {\beta }_g^*)\right \}$ is the error set and ${\cal  C}_g = \text  {Cone}({\cal  E}_g)$ is the error cone. For all $i,j$, SC requires $-{\cal  C}_i \cap {\cal  C}_j = \{0\}$. In panel (a) we only show this condition for $i = 0$, i.e., $-{\cal  C}_0 \cap {\cal  C}_j = \{0\}$ where all $\theta _j > 0$. {\sc  Dashin}on the other hand only needs one of the ${\cal  C}_g, g \in [G],$ does not intersect with the inverse of the common parameter error cone $-{\cal  C}_0$. In panel (b) $-{\cal  C}_0 \cap {\cal  C}_1 = \{0\}$ is enough for recovering all parameters.\relax }}{5}{figure.caption.13}\protected@file@percent }
\newlabel{fig syn2}{{2}{5}{Comparison of geometric recovery condition for superposition models known as Structural Coherence (SC) \cite {guba16} and our \ds \ recovery condition for data sharing model which is a system of coupled superposition models \eqref {eq:dirtymodel}. For each parameter $\bbeta ^*_g \in [G]$, $\cE _g = \left \{\ddelta _g | f_g(\bbeta _g^* + \ddelta _g) \leq f_g(\bbeta _g^*)\right \}$ is the error set and $\cC _g = \text {Cone}(\cE _g)$ is the error cone. For all $i,j$, SC requires $-\cC _i \cap \cC _j = \{0\}$. In panel (a) we only show this condition for $i = 0$, i.e., $-\cC _0 \cap \cC _j = \{0\}$ where all $\theta _j > 0$. \ds on the other hand only needs one of the $\cC _g, g \in [G],$ does not intersect with the inverse of the common parameter error cone $-\cC _0$. In panel (b) $-\cC _0 \cap \cC _1 = \{0\}$ is enough for recovering all parameters.\relax }{figure.caption.13}{}}
\newlabel{fig syn2@cref}{{[figure][2][]2}{[1][4][]5}}
\newlabel{sec:esti}{{2}{5}{The Data Shared Estimator}{section.14}{}}
\newlabel{sec:esti@cref}{{[section][2][]2}{[1][4][]5}}
\@writefile{toc}{\contentsline {section}{\numberline {2}The Data Shared Estimator}{5}{section.14}\protected@file@percent }
\newlabel{eq:compact}{{2.1}{5}{The Data Shared Estimator}{equation.15}{}}
\newlabel{eq:compact@cref}{{[equation][1][2]2.1}{[1][4][]5}}
\newlabel{eq:x}{{2.2}{5}{The Data Shared Estimator}{equation.16}{}}
\newlabel{eq:x@cref}{{[equation][2][2]2.2}{[1][5][]5}}
\@writefile{thm}{\contentsline {example}{{Example}{2.1}{}}{5}{theorem.17}\protected@file@percent }
\newlabel{exm:sde}{{2.1}{5}{The Data Shared Estimator}{theorem.17}{}}
\newlabel{exm:sde@cref}{{[example][1][2]2.1}{[1][5][]5}}
\citation{banerjee14}
\citation{nrwy12}
\citation{raskutti10}
\citation{guba16}
\citation{mend15}
\citation{trop15}
\citation{banerjee14}
\citation{ruzh13}
\newlabel{setH}{{2.5}{6}{The Data Shared Estimator}{equation.20}{}}
\newlabel{setH@cref}{{[equation][5][2]2.5}{[1][6][]6}}
\@writefile{thm}{\contentsline {theorem}{{Theorem}{2.2}{}}{6}{theorem.21}\protected@file@percent }
\newlabel{theo:deter}{{2.2}{6}{The Data Shared Estimator}{theorem.21}{}}
\newlabel{theo:deter@cref}{{[theorem][2][2]2.2}{[1][6][]6}}
\@writefile{thm}{\contentsline {proof}{{Proof}{1}{}}{6}{proof.23}\protected@file@percent }
\newlabel{eq:tre}{{2.6}{6}{The Data Shared Estimator}{equation.24}{}}
\newlabel{eq:tre@cref}{{[equation][6][2]2.6}{[1][6][]6}}
\newlabel{eq:tub}{{2.7}{6}{The Data Shared Estimator}{equation.25}{}}
\newlabel{eq:tub@cref}{{[equation][7][2]2.7}{[1][6][]6}}
\@writefile{thm}{\contentsline {remark}{{Remark}{2.3}{}}{6}{theorem.26}\protected@file@percent }
\newlabel{rem1}{{2.3}{6}{The Data Shared Estimator}{theorem.26}{}}
\newlabel{rem1@cref}{{[remark][3][2]2.3}{[1][6][]6}}
\citation{guba16}
\citation{mctr13}
\citation{guba16}
\citation{mctr13}
\citation{guba16}
\citation{trop15}
\newlabel{sec:re}{{3}{7}{Restricted Eigenvalue Condition}{section.28}{}}
\newlabel{sec:re@cref}{{[section][3][]3}{[1][6][]7}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Restricted Eigenvalue Condition}{7}{section.28}\protected@file@percent }
\@writefile{thm}{\contentsline {definition}{{Definition}{3.1}{}}{7}{theorem.30}\protected@file@percent }
\newlabel{def:obs}{{3.1}{7}{Restricted Eigenvalue Condition}{theorem.30}{}}
\newlabel{def:obs@cref}{{[definition][1][3]3.1}{[1][7][]7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Geometric Condition for Recovery}{7}{subsection.31}\protected@file@percent }
\@writefile{thm}{\contentsline {definition}{{Definition}{3.2}{Structural Coherence (SC) \cite {guba16, mctr13}}}{7}{theorem.32}\protected@file@percent }
\newlabel{scc}{{3.2}{7}{Geometric Condition for Recovery}{theorem.32}{}}
\newlabel{scc@cref}{{[definition][2][3]3.2}{[1][7][]7}}
\@writefile{thm}{\contentsline {remark}{{Remark}{3.3}{}}{7}{theorem.33}\protected@file@percent }
\@writefile{thm}{\contentsline {definition}{{Definition}{3.4}{DAta SHaring Incoherence conditioN (\ds )}}{7}{theorem.35}\protected@file@percent }
\newlabel{incodef}{{3.4}{7}{Geometric Condition for Recovery}{theorem.35}{}}
\newlabel{incodef@cref}{{[definition][4][3]3.4}{[1][7][]7}}
\citation{mend15}
\citation{banerjee14}
\citation{vershynin2018high}
\citation{jrsr10}
\@writefile{thm}{\contentsline {remark}{{Remark}{3.5}{}}{8}{theorem.38}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Sample Complexity}{8}{subsection.39}\protected@file@percent }
\@writefile{thm}{\contentsline {prop}{{Proposition}{3.6}{}}{8}{theorem.40}\protected@file@percent }
\newlabel{prop:super}{{3.6}{8}{Sample Complexity}{theorem.40}{}}
\newlabel{prop:super@cref}{{[prop][6][3]3.6}{[1][8][]8}}
\@writefile{thm}{\contentsline {theorem}{{Theorem}{3.7}{}}{8}{theorem.41}\protected@file@percent }
\newlabel{theo:re}{{3.7}{8}{Sample Complexity}{theorem.41}{}}
\newlabel{theo:re@cref}{{[theorem][7][3]3.7}{[1][8][]8}}
\@writefile{thm}{\contentsline {remark}{{Remark}{3.8}{}}{8}{theorem.43}\protected@file@percent }
\@writefile{thm}{\contentsline {example}{{Example}{3.9}{}}{8}{theorem.44}\protected@file@percent }
\citation{boucheron13}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Comparison of the order of per group number of samples (sample complexities) of various methods for recovering sparse DS parameters. Let $s_{0g} = |\text  {support}(\bm  {\beta }^*_0 + \bm  {\beta }^*_g)|$ be the superimposed support where $s_0, s_g \leq \qopname  \relax m{max}(s_0, s_g) \leq s_{0g}$.\relax }}{9}{table.caption.45}\protected@file@percent }
\newlabel{compare}{{1}{9}{Comparison of the order of per group number of samples (sample complexities) of various methods for recovering sparse DS parameters. Let $s_{0g} = |\text {support}(\bbeta ^*_0 + \bbeta ^*_g)|$ be the superimposed support where $s_0, s_g \leq \max (s_0, s_g) \leq s_{0g}$.\relax }{table.caption.45}{}}
\newlabel{compare@cref}{{[table][1][]1}{[1][8][]9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Proof of \cref  {theo:re}}{9}{subsection.46}\protected@file@percent }
\newlabel{eq:long}{{3.1}{9}{Proof of \cref {theo:re}}{equation.48}{}}
\newlabel{eq:long@cref}{{[equation][1][3]3.1}{[1][9][]9}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}Lower Bounding the First Term}{9}{subsubsection.49}\protected@file@percent }
\@writefile{thm}{\contentsline {lemma}{{Lemma}{3.10}{}}{9}{theorem.50}\protected@file@percent }
\newlabel{lemm:shareInc}{{3.10}{9}{Lower Bounding the First Term}{theorem.50}{}}
\newlabel{lemm:shareInc@cref}{{[lemma][10][3]3.10}{[1][9][]9}}
\newlabel{eq:rhs}{{3.2}{9}{Lower Bounding the First Term}{equation.51}{}}
\newlabel{eq:rhs@cref}{{[equation][2][3]3.2}{[1][9][]9}}
\citation{boucheron13}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2}Upper Bounding the Second Term}{10}{subsubsection.52}\protected@file@percent }
\@writefile{thm}{\contentsline {lemma}{{Lemma}{3.11}{}}{10}{theorem.54}\protected@file@percent }
\newlabel{lemm:secTerm}{{3.11}{10}{Upper Bounding the Second Term}{theorem.54}{}}
\newlabel{lemm:secTerm@cref}{{[lemma][11][3]3.11}{[1][10][]10}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.3}Continuing the Proof of \cref  {theo:re}}{10}{subsubsection.56}\protected@file@percent }
\newlabel{sec:error}{{4}{11}{General Error Bound}{section.58}{}}
\newlabel{sec:error@cref}{{[section][4][]4}{[1][11][]11}}
\@writefile{toc}{\contentsline {section}{\numberline {4}General Error Bound}{11}{section.58}\protected@file@percent }
\@writefile{thm}{\contentsline {theorem}{{Theorem}{4.1}{}}{11}{theorem.59}\protected@file@percent }
\newlabel{theo:calcub}{{4.1}{11}{General Error Bound}{theorem.59}{}}
\newlabel{theo:calcub@cref}{{[theorem][1][4]4.1}{[1][11][]11}}
\newlabel{eq:general}{{4.1}{11}{General Error Bound}{equation.60}{}}
\newlabel{eq:general@cref}{{[theorem][1][4]4.1}{[1][11][]11}}
\@writefile{thm}{\contentsline {corollary}{{Corollary}{4.2}{}}{11}{theorem.61}\protected@file@percent }
\newlabel{corr:single}{{4.2}{11}{General Error Bound}{theorem.61}{}}
\newlabel{corr:single@cref}{{[corollary][2][4]4.2}{[1][11][]11}}
\@writefile{thm}{\contentsline {example}{{Example}{4.3}{}}{11}{theorem.63}\protected@file@percent }
\citation{banerjee14}
\citation{bickel2009simultaneous}
\citation{candes2007dantzig}
\citation{venkat12}
\citation{chatterjee2014generalized}
\@writefile{thm}{\contentsline {example}{{Example}{4.4}{}}{12}{theorem.65}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Proof of \cref  {theo:calcub}}{12}{subsection.67}\protected@file@percent }
\newlabel{eq:maxex}{{4.4}{12}{Proof of \cref {theo:calcub}}{equation.70}{}}
\newlabel{eq:maxex@cref}{{[equation][4][4]4.4}{[1][12][]12}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {5.1}{\ignorespaces  {\sc  Dasher}\relax }}{13}{algorithm.75}\protected@file@percent }
\newlabel{alg2}{{5.1}{13}{\dc \relax }{algorithm.75}{}}
\newlabel{alg2@cref}{{[algorithm][1][5]5.1}{[1][13][]13}}
\@writefile{thm}{\contentsline {lemma}{{Lemma}{4.5}{}}{13}{theorem.72}\protected@file@percent }
\newlabel{lemm:mainlem}{{4.5}{13}{Proof of \cref {theo:calcub}}{theorem.72}{}}
\newlabel{lemm:mainlem@cref}{{[lemma][5][4]4.5}{[1][13][]13}}
\newlabel{sec:opt}{{5}{13}{Estimation Algorithm}{section.74}{}}
\newlabel{sec:opt@cref}{{[section][5][]5}{[1][13][]13}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Estimation Algorithm}{13}{section.74}\protected@file@percent }
\@writefile{thm}{\contentsline {definition}{{Definition}{5.1}{}}{13}{theorem.84}\protected@file@percent }
\newlabel{def:only}{{5.1}{13}{Estimation Algorithm}{theorem.84}{}}
\newlabel{def:only@cref}{{[definition][1][5]5.1}{[1][13][]13}}
\@writefile{thm}{\contentsline {theorem}{{Theorem}{5.2}{}}{14}{theorem.86}\protected@file@percent }
\newlabel{theo:iter}{{5.2}{14}{Estimation Algorithm}{theorem.86}{}}
\newlabel{theo:iter@cref}{{[theorem][2][5]5.2}{[1][13][]14}}
\@writefile{thm}{\contentsline {proof}{{Proof}{2}{}}{14}{proof.88}\protected@file@percent }
\@writefile{thm}{\contentsline {lemma}{{Lemma}{5.3}{}}{14}{theorem.89}\protected@file@percent }
\newlabel{lem:recurse}{{5.3}{14}{Estimation Algorithm}{theorem.89}{}}
\newlabel{lem:recurse@cref}{{[lemma][3][5]5.3}{[1][14][]14}}
\newlabel{eq:singleiter}{{5.2}{14}{Estimation Algorithm}{equation.92}{}}
\newlabel{eq:singleiter@cref}{{[equation][2][5]5.2}{[1][14][]14}}
\global\def\markiiproofii{\proofbox }
\@writefile{thm}{\contentsline {theorem}{{Theorem}{5.4}{}}{15}{theorem.93}\protected@file@percent }
\newlabel{theo:step}{{5.4}{15}{Estimation Algorithm}{theorem.93}{}}
\newlabel{theo:step@cref}{{[theorem][4][5]5.4}{[1][15][]15}}
\@writefile{thm}{\contentsline {corollary}{{Corollary}{5.5}{}}{15}{theorem.96}\protected@file@percent }
\newlabel{corr:show}{{5.5}{15}{Estimation Algorithm}{theorem.96}{}}
\newlabel{corr:show@cref}{{[corollary][5][5]5.5}{[1][15][]15}}
\newlabel{eq:scaled}{{5.3}{15}{Estimation Algorithm}{equation.97}{}}
\newlabel{eq:scaled@cref}{{[equation][3][5]5.3}{[1][15][]15}}
\newlabel{proofsketch}{{5.1}{15}{Proof Sketch of \cref {theo:step}}{subsection.98}{}}
\newlabel{proofsketch@cref}{{[subsection][1][5]5.1}{[1][15][]15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Proof Sketch of \cref  {theo:step}}{15}{subsection.98}\protected@file@percent }
\@writefile{thm}{\contentsline {lemma}{{Lemma}{5.6}{}}{16}{theorem.99}\protected@file@percent }
\newlabel{lemm:hpub}{{5.6}{16}{Proof Sketch of \cref {theo:step}}{theorem.99}{}}
\newlabel{lemm:hpub@cref}{{[lemma][6][5]5.6}{[1][15][]16}}
\newlabel{fig syn1a}{{3a}{17}{$n_g = 60$, $\w = 0$\relax }{figure.caption.104}{}}
\newlabel{fig syn1a@cref}{{[subfigure][1][3]3a}{[1][17][]17}}
\newlabel{sub@fig syn1a}{{a}{17}{$n_g = 60$, $\w = 0$\relax }{figure.caption.104}{}}
\newlabel{sub@fig syn1a@cref}{{[subfigure][1][3]3a}{[1][17][]17}}
\newlabel{fig syn1b}{{3b}{17}{$n_g = 60$, $\w _1 \neq 0$\relax }{figure.caption.104}{}}
\newlabel{fig syn1b@cref}{{[subfigure][2][3]3b}{[1][17][]17}}
\newlabel{sub@fig syn1b}{{b}{17}{$n_g = 60$, $\w _1 \neq 0$\relax }{figure.caption.104}{}}
\newlabel{sub@fig syn1b@cref}{{[subfigure][2][3]3b}{[1][17][]17}}
\newlabel{fig syn2a}{{3c}{17}{$n_g = 150$, $\w = 0$\relax }{figure.caption.104}{}}
\newlabel{fig syn2a@cref}{{[subfigure][3][3]3c}{[1][17][]17}}
\newlabel{sub@fig syn2a}{{c}{17}{$n_g = 150$, $\w = 0$\relax }{figure.caption.104}{}}
\newlabel{sub@fig syn2a@cref}{{[subfigure][3][3]3c}{[1][17][]17}}
\newlabel{fig syn2b}{{3d}{17}{$n_g = 150$, $\w = 0$\relax }{figure.caption.104}{}}
\newlabel{fig syn2b@cref}{{[subfigure][4][3]3d}{[1][17][]17}}
\newlabel{sub@fig syn2b}{{d}{17}{$n_g = 150$, $\w = 0$\relax }{figure.caption.104}{}}
\newlabel{sub@fig syn2b@cref}{{[subfigure][4][3]3d}{[1][17][]17}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces In (a), (b), and (c) experiments $p = 100$, $G = 10$, $\forall g \in [G]: s_g = 10$, and $s_0 = p$. For (d) $p = 1000$, $G = 100$, $\forall g \in [G]: s_g = 10$, and $s_0 = 100$. (a) Noiseless fast convergence. (b) Noise on the first group does not impact other groups as much. (c) Increasing sample size improves rate of convergence. (d) {\sc  Dasher}\ convergences fast even with a large number of groups $G=100$.\relax }}{17}{figure.caption.104}\protected@file@percent }
\newlabel{fig syn12}{{3}{17}{In (a), (b), and (c) experiments $p = 100$, $G = 10$, $\forall g \in [G]: s_g = 10$, and $s_0 = p$. For (d) $p = 1000$, $G = 100$, $\forall g \in [G]: s_g = 10$, and $s_0 = 100$. (a) Noiseless fast convergence. (b) Noise on the first group does not impact other groups as much. (c) Increasing sample size improves rate of convergence. (d) \dc \ convergences fast even with a large number of groups $G=100$.\relax }{figure.caption.104}{}}
\newlabel{fig syn12@cref}{{[figure][3][]3}{[1][17][]17}}
\newlabel{sec:expds}{{6}{17}{Experiments on Synthetic Data}{section.105}{}}
\newlabel{sec:expds@cref}{{[section][6][]6}{[1][17][]17}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Experiments on Synthetic Data}{17}{section.105}\protected@file@percent }
\bibstyle{siamplain}
\bibdata{nips18}
\bibcite{asiaee2018high}{1}
\bibcite{asiaeedata}{2}
\bibcite{bach2012optimization}{3}
\bibcite{banerjee14}{4}
\bibcite{barretina2012cancer}{5}
\bibcite{bickel2009simultaneous}{6}
\bibcite{blumensath2009iterative}{7}
\bibcite{boucheron13}{8}
\bibcite{boufounos20081}{9}
\bibcite{candes2007dantzig}{10}
\bibcite{candes2009exact}{11}
\bibcite{candes2006robust}{12}
\bibcite{candes2010power}{13}
\bibcite{venkat12}{14}
\bibcite{chatterjee2014generalized}{15}
\bibcite{Chen2015-fj}{16}
\bibcite{Chen2012-fb}{17}
\bibcite{domu16}{18}
\bibcite{donoho2006compressed}{19}
\bibcite{friedman2008sparse}{20}
\bibcite{grti16}{21}
\bibcite{guba16}{22}
\bibcite{iorio2016landscape1}{23}
\bibcite{jain2013low}{24}
\bibcite{jrsr10}{25}
\bibcite{Kakade2010-st}{26}
\bibcite{mctr13}{27}
\bibcite{mend15}{28}
\bibcite{negahban2012restricted}{29}
\bibcite{negahban2009unified}{30}
\bibcite{nrwy12}{31}
\bibcite{olvi14}{32}
\bibcite{olvi15}{33}
\bibcite{Plan2013-nx}{34}
\bibcite{Plan2016-de}{35}
\bibcite{plan2017high}{36}
\bibcite{raskutti10}{37}
\bibcite{ruzh13}{38}
\bibcite{tibshirani1996regression}{39}
\bibcite{trop15}{40}
\bibcite{vers12}{41}
\bibcite{vershynin2018high}{42}
\bibcite{Yang2013-pf}{43}
\bibcite{Yang2016-zd}{44}
\bibcite{Zhang2017-rm}{45}
