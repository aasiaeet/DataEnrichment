---
title: "Reading All Data"
author: "Amir Asiaee"
date: "12 July 2019"
output:
  html_document:
    toc: true
    theme: yeti
    highlight: kate
---
  
```{r setup, include=FALSE, results="hide"}
knitr::opts_chunk$set(echo = TRUE)
```
```{r mycss, results="asis", echo=FALSE}
cat('
<style type="text/css">
b, strong {color: red; }
i, em {color: blue; }
.defn {color: purple; }
.para {color: purple;
      font-weight: bold;
}
.figure { text-align: center; }
.caption { font-weight: bold; }
</style>
')
```
# This report is deprecated. Go to files starting with 4.

# Executive Summary
## Background
The **overall** goal of this project is to run DICER on CCLE data. 

The **immediate** goal of this report is to read in the saved clean data into separate file for each cancer and generate $(X_g, y_g)$ pairs. We do this in two ways:

- Groups are representing cancer type. 
- Groups are sub-types. 

## Methods

### Input Data
We are using outputs of `01-readingData.Rmd` saved in `paths$clean`. 

### Output Data 


### Statistics

## Results

## Conclusion


# Setting up Basics

First we prepare the paths for the data. 
```{r paths}
rm(list = ls())
source("00-paths.R")
```

# Cross-validation
We define variables to store the results of cross-validation:
```{r results}
load(file.path(paths$clean, "doseResponse.RData", sep=""))
drugs <- doseResponse$compound
corrThresh <- 0.1
nl <- 100 #number of lambda (tuning param) tested

cvMeans <- matrix(NA, nrow = length(drugs), ncol = nl)
rownames(cvMeans) <- drugs
#colnames(cvMeans) <- paste("lambda=", myLambda)
cvSds <- matrix(NA, nrow = length(drugs), ncol = nl)
rownames(cvSds) <- drugs
#colnames(cvMeans) <- paste("lambda=", myLambda)
```

Now the actual work:
```{r cv}
K <- 10 #num of folds
set.seed(123)
for(drug in unique(drugs)){
  load(file=file.path(paths$clean, paste("xy_", drug, ".Rda", sep="")))
  n <- dim(X)[1]
  p <- dim(X)[2]
  # First we find a good range of regularization parameter:
  alpha <- 1
  lambdaMax <- sapply(X, function(x,y) 1/(alpha * length(y)) * abs(sum(x*y)), yIC50)
  lambdaMin <- 0.001 * lambdaMax
  myLambda <- exp(1)^seq(log(lambdaMin), log(lambdaMax), length.out = nl)
  foldsId <- sample(rep(1:K, length.out = n))
  for (k in 1:K) {
    print(paste("Fold", k, "started."))
    # ptm <- proc.time()
    testId <- which(foldsId == k)
    trainX <- X[-testId, ]
    trainY <- yIC50[-testId]
    testX <- X[testId, ]
    testY <- yIC50[testId]
    
    # Using train data to trim features: Don't use test, bc you'll leak info from test to train. 
    correlations <- sapply(trainX, cor, y=trainY)
    # Marking features with variance zero
    correlations[sapply(correlations, is.na)] <- 0
    # Removing less relevant features 
    mask <- (abs(correlations) >= corrThresh) 
    bestTrainX <- trainX[,mask]
    bestTestX <- testX[,mask]
    # print("Number of features has reduced to", dim(bestTrainX)[2])
    
    lassoFit <- glmnet(x = as.matrix(bestTrainX), y = trainY, alpha=1, lambda = myLambda)
    yHat <- predict(lassoFit, newx=as.matrix(bestTestX)) 
    err <- sapply(as.data.frame(yHat), function(x,y) mean((x - y)^2), testY)
    cvResults[k, ] <- err
  }
  cvMeans[drug,] <-  colMeans(cvResults)
  cvSds[drug,] <- apply(cvResults, 2, sd)
  cvMinLambda <- myLambda[which.min(cvMeans[drug,])]
  
  finalCorr <- sapply(X, cor, yIC50)
  finalCorr[sapply(finalCorr, is.na)] <- 0
  finalMask <- (abs(finalCorr) >= corrThresh) 
  bestX <- X[,finalMask]
  finalFit <- glmnet(x = as.matrix(bestX), y = yIC50, alpha=1, lambda = cvMinLambda)
  print("Number of non-zero coeffs:", finalFit$df)
  print("L_1 norm of beta:", sum(abs(finalFit$beta)))
  
  save(foldsId, cvMinLambda, finalMask, finalFit, file=file.path(paths$clean, paste("lassoRes_", drug, ".Rda", sep="")))
}
```

```{r}
for(file in allFiles){
  
  
  # Determining lambda.
  lambdaMax <- .5 #max(sapply(predictors, function(x,y) abs(sum(x * y)), response)) / nTrain
  lambdaMin <- .001 * lambdaMax
  myLambda <- exp(1)^seq(log(lambdaMin), log(lambdaMax), length.out = 10)
  
  cvResults <- matrix(NA, nrow = nfolds, ncol = numLambda)
  lowestErrs <- c()
  for (k in 1:nfolds) {
    print(paste("Fold", k, "started."))
    # ptm <- proc.time()
    testId <- which(foldsId == k)
    trainX <- predictors[-testId, ]
    trainY <- response[-testId]
    testX <- predictors[testId, ]
    testY <- response[testId]
    
    # Using train data to trim features: Don't use test, bc you'll leak info from test to train. 
    ## Removing features with variance zero
    zeroVarFeatureIndex <- (sapply(trainX, var) <= .02^2)
    trainX <- trainX[, !zeroVarFeatureIndex]
    testX <- testX[, !zeroVarFeatureIndex]
    ## Removing less relevant features 
    correlations <- sapply(trainX, cor, y=trainY)
    # correlations[sapply(correlations, is.na)] <- 0
    # print(paste("Here is number of NA in corr:", sum(sapply(correlations, is.na))))
    mask <- (abs(correlations) >= corrThresh) 
    bestTrainX <- trainX[,mask]
    bestTestX <- testX[,mask]
    print(dim(bestTrainX))
    
    
    # glmnetFit <- glmnet(x = as.matrix(bestTrainX), y = trainY, alpha=2/3, lambda = myLambda)
    glmnetFit <- glmnet(x = as.matrix(bestTrainX), y = trainY, alpha=1, lambda = myLambda)
    yHat <- predict(glmnetFit, newx=as.matrix(bestTestX),s=myLambda) # make predictions
    err <- sapply(as.data.frame(yHat), function(x,y) mean((x - y)^2), testY)
    cvResults[k, ] <- err
    # print(paste("Done with the elastic net on fold", k))
  }
  cvMeans[drugName,] <-  colMeans(cvResults)
  cvSds[drugName,] <- apply(cvResults, 2, sd)
  cvMinLambdas[drugName] <- myLambda[which.min(cvMeans[drugName,])]
  cvLambdas[drugName,] <- myLambda
  print(min(cvMeans[drugName,]))
  
  # par(mar=c(4,4,4,4))
  # plot(log(cv1005$lambda),cv1005$cvm,pch=19,col="red",xlab="log(Lambda)",ylab=cv1005$name)
  # print("Done plotting the results!")
  #   
  ############################
  # This is for important feature selection. Disabled for now.
  ############################
  
  #   print("Starting the bootstrap!")
  #   runningSumOfImpIndex <- matrix(0L, nrow = ncol(data), ncol = 1)
  #   numBootStrap <- 50
  #   for(i in 1:numBootStrap){
  #     print(paste("Resample number ", i))
  #     bootStrapSampleIndex <- sample(1:nrow(data), nrow(data), replace=TRUE)
  #     bootStrapData <- data[bootStrapSampleIndex,]
  #     bootStrapCv1005 <- myElasticNetRegression(bootStrapData, savedLambda.min)
  #     runningSumOfImpIndex <- runningSumOfImpIndex + as.integer(abs(as.matrix(coef(bootStrapCv1005))) >0.00000001)
  #   }
  
  #readline(print("Stop!"))
  
  #avgFreqOfImpIndex <- runningSumOfImpIndex / numBootStrap
  #impFeatureIndex <- (avgFreqOfImpIndex >= .5)
  
  #valueOfCoef <- as.matrix(coef(cv1005, s="lambda.min"))
  #valueOfImpCoef <- valueOfCoef[impFeatureIndex]
  #nameOfImpCoef <- rownames(valueOfCoef)[impFeatureIndex]
  #sortedValueOfImpCoef <- sort(valueOfImpCoef, decreasing = TRUE, index.return=TRUE)
  #print(nameOfImpCoef[sortedValueOfImpCoef$ix])
  ############################
  
  # readline(print("Should I go to the next drug?!"))
}
save(cvMeans, file=file.path(paths$scratch, paste("new_cvMeans_", paste(focusedCancerTypes, corrThresh, collapse = "_") ,".RData")))
save(cvSds, file=file.path(paths$scratch, paste("new_cvSds_", paste(focusedCancerTypes, corrThresh, collapse = "_") ,".RData")))
save(cvLambdas, file=file.path(paths$scratch, paste("new_cvLambdas_", paste(focusedCancerTypes, corrThresh, collapse = "_") ,".RData")))
save(cvMinLambdas, file=file.path(paths$scratch, paste("new_cvMinLambdas_", paste(focusedCancerTypes, corrThresh, collapse = "_") ,".RData")))



# }
```

# Appendix
This analysis was performed in this environment:
```{r si}
sessionInfo()
```
