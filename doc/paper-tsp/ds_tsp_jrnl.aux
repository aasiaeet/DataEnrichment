\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{candes2010power}
\citation{donoho2006compressed}
\citation{friedman2008sparse}
\citation{candes2009exact}
\citation{candes2006robust}
\citation{tibshirani1996regression}
\citation{bach2012optimization}
\citation{negahban2009unified}
\citation{boufounos20081}
\citation{plan2017high}
\citation{blumensath2009iterative}
\citation{jain2013low}
\citation{barretina2012cancer}
\citation{iorio2016landscape1}
\citation{guba16}
\citation{mctr13}
\citation{Yang2013-pf}
\citation{jrsr10}
\citation{Zhang2017-rm}
\citation{grti16}
\citation{asiaee2018high}
\citation{asiaeedata}
\citation{Chen2015-fj}
\citation{domu16}
\citation{grti16}
\citation{olvi14}
\citation{olvi15}
\citation{Kakade2010-st}
\citation{negahban2012restricted}
\citation{Plan2013-nx}
\citation{Plan2016-de}
\citation{Yang2016-zd}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{section.1}\protected@file@percent }
\newlabel{eq:dsl}{{1}{1}{Introduction}{equation.1.1}{}}
\citation{Zhang2017-rm}
\citation{Chen2012-fb}
\citation{jrsr10}
\citation{jrsr10}
\citation{domu16}
\citation{grti16}
\citation{olvi15}
\citation{olvi14}
\citation{domu16}
\citation{grti16}
\citation{olvi14}
\citation{olvi15}
\citation{olvi15}
\citation{jrsr10}
\citation{vers12}
\citation{vers12}
\citation{vershynin2018high}
\citation{guba16}
\citation{mctr13}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {I-A}}Related Work}{2}{subsection.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {I-B}}Notation and Preliminaries}{2}{subsection.1.2}\protected@file@percent }
\newlabel{eq:dirtymodel}{{2}{2}{Notation and Preliminaries}{equation.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {I-C}}Our Contributions}{2}{subsection.1.3}\protected@file@percent }
\newlabel{eq:super}{{3}{2}{Our Contributions}{equation.1.3}{}}
\citation{guba16}
\citation{guba16}
\newlabel{eq:errorsum}{{4}{3}{Our Contributions}{equation.1.4}{}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:sc}{{1a}{3}{Structural Coherence (SC) condition.\relax }{figure.caption.1}{}}
\newlabel{sub@fig:sc}{{a}{3}{Structural Coherence (SC) condition.\relax }{figure.caption.1}{}}
\newlabel{fig:DASHIN}{{1b}{3}{DAta SHaring Incoherence conditioN (\ds ).\relax }{figure.caption.1}{}}
\newlabel{sub@fig:DASHIN}{{b}{3}{DAta SHaring Incoherence conditioN (\ds ).\relax }{figure.caption.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \relax \fontsize  {9}{10pt}\selectfont  Comparison of geometric recovery condition for superposition models known as Structural Coherence (SC) \cite  {guba16} and our {\sc  Dashin}\ recovery condition for data sharing model which is a system of coupled superposition models \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces \ref  {eq:dirtymodel}\unskip \@@italiccorr )}}. For each parameter $\bm  {\beta }^*_g \in [G]$, ${\cal  E}_g = \left \{\bm  {\delta }_g | f_g(\bm  {\beta }_g^* + \bm  {\delta }_g) \leq f_g(\bm  {\beta }_g^*)\right \}$ is the error set and ${\cal  C}_g = \text  {Cone}({\cal  E}_g)$ is the error cone. For all $i,j$, SC requires $-{\cal  C}_i \cap {\cal  C}_j = \{0\}$. In panel (a) we only show this condition for $i = 0$, i.e., $-{\cal  C}_0 \cap {\cal  C}_j = \{0\}$ where all $\theta _j > 0$. (b) {\sc  Dashin}\ only needs one of the ${\cal  C}_g, g \in [G],$ does not intersect with the inverse of the common parameter error cone $-{\cal  C}_0$. In panel (b) $-{\cal  C}_0 \cap {\cal  C}_1 = \{0\}$ is enough for recovering all parameters.\relax }}{3}{figure.caption.1}\protected@file@percent }
\newlabel{fig syn2}{{1}{3}{\small Comparison of geometric recovery condition for superposition models known as Structural Coherence (SC) \cite {guba16} and our \ds \ recovery condition for data sharing model which is a system of coupled superposition models \eqref {eq:dirtymodel}. For each parameter $\bbeta ^*_g \in [G]$, $\cE _g = \left \{\ddelta _g | f_g(\bbeta _g^* + \ddelta _g) \leq f_g(\bbeta _g^*)\right \}$ is the error set and $\cC _g = \text {Cone}(\cE _g)$ is the error cone. For all $i,j$, SC requires $-\cC _i \cap \cC _j = \{0\}$. In panel (a) we only show this condition for $i = 0$, i.e., $-\cC _0 \cap \cC _j = \{0\}$ where all $\theta _j > 0$. (b) \ds \ only needs one of the $\cC _g, g \in [G],$ does not intersect with the inverse of the common parameter error cone $-\cC _0$. In panel (b) $-\cC _0 \cap \cC _1 = \{0\}$ is enough for recovering all parameters.\relax }{figure.caption.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {II}The Data Shared Estimator}{3}{section.2}\protected@file@percent }
\newlabel{sec:esti}{{II}{3}{The Data Shared Estimator}{section.2}{}}
\newlabel{eq:compact}{{5}{3}{The Data Shared Estimator}{equation.2.5}{}}
\newlabel{eq:x}{{6}{3}{The Data Shared Estimator}{equation.2.6}{}}
\newlabel{exm:sde}{{1}{3}{The Data Shared Estimator}{example.1}{}}
\newlabel{setH}{{7}{3}{The Data Shared Estimator}{equation.2.7}{}}
\newlabel{theo:deter}{{1}{3}{The Data Shared Estimator}{theorem.1}{}}
\citation{banerjee14}
\citation{nrwy12}
\citation{raskutti10}
\citation{guba16}
\citation{mend15}
\citation{trop15}
\citation{banerjee14}
\citation{ruzh13}
\citation{guba16}
\citation{mctr13}
\citation{guba16}
\citation{mctr13}
\citation{guba16}
\citation{trop15}
\newlabel{eq:tre}{{8}{4}{The Data Shared Estimator}{equation.2.8}{}}
\newlabel{eq:tub}{{9}{4}{The Data Shared Estimator}{equation.2.9}{}}
\newlabel{rem1}{{1}{4}{The Data Shared Estimator}{remark.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Restricted Eigenvalue Condition}{4}{section.3}\protected@file@percent }
\newlabel{sec:re}{{III}{4}{Restricted Eigenvalue Condition}{section.3}{}}
\newlabel{def:obs}{{1}{4}{Restricted Eigenvalue Condition}{definition.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-A}}Geometric Condition for Recovery}{4}{subsection.3.1}\protected@file@percent }
\newlabel{scc}{{2}{4}{Structural Coherence (SC) \cite {guba16, mctr13}}{definition.2}{}}
\newlabel{incodef}{{3}{4}{DAta SHaring Incoherence conditioN (\ds )}{definition.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-B}}Sample Complexity}{4}{subsection.3.2}\protected@file@percent }
\newlabel{prop:super}{{2}{4}{Sample Complexity}{theorem.2}{}}
\citation{mend15}
\citation{banerjee14}
\citation{vershynin2018high}
\citation{jrsr10}
\citation{trop15}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces \relax \fontsize  {9}{10pt}\selectfont  Comparison of the order of per group number of samples (sample complexities) of various methods for recovering sparse DS parameters. Let $s_{0g} = |\text  {support}(\bm  {\beta }^*_0 + \bm  {\beta }^*_g)|$ be the superimposed support where $s_0, s_g \leq \qopname  \relax m{max}(s_0, s_g) \leq s_{0g}$.\relax }}{5}{table.caption.2}\protected@file@percent }
\newlabel{compare}{{I}{5}{\small Comparison of the order of per group number of samples (sample complexities) of various methods for recovering sparse DS parameters. Let $s_{0g} = |\text {support}(\bbeta ^*_0 + \bbeta ^*_g)|$ be the superimposed support where $s_0, s_g \leq \max (s_0, s_g) \leq s_{0g}$.\relax }{table.caption.2}{}}
\newlabel{theo:re}{{3}{5}{Sample Complexity}{theorem.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-C}}Proof of Theorem \ref  {theo:re}}{5}{subsection.3.3}\protected@file@percent }
\newlabel{eq:long}{{10}{5}{Proof of Theorem \ref {theo:re}}{equation.3.10}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {III-C}1}Lower Bounding the First Term $t_1(\mathbf  {X})$}{5}{subsubsection.3.3.1}\protected@file@percent }
\newlabel{incolem main}{{4}{5}{Lower Bounding the First Term $t_1(\X )$}{theorem.4}{}}
\citation{boucheron13}
\citation{boucheron13}
\citation{trop15}
\citation{trop15}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {III-C}2}Upper Bounding the Second Term $t_2(\mathbf  {X})$}{6}{subsubsection.3.3.2}\protected@file@percent }
\newlabel{lemm:secTerm}{{5}{6}{Upper Bounding the Second Term $t_2(\X )$}{theorem.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {III-C}3}Continuing the Proof of Theorem \ref  {theo:re}}{6}{subsubsection.3.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {IV}General Error Bound}{6}{section.4}\protected@file@percent }
\newlabel{sec:error}{{IV}{6}{General Error Bound}{section.4}{}}
\newlabel{theo:calcub}{{6}{6}{General Error Bound}{theorem.6}{}}
\newlabel{eq:general}{{11}{6}{General Error Bound}{equation.4.11}{}}
\citation{banerjee14}
\citation{bickel2009simultaneous}
\citation{candes2007dantzig}
\citation{venkat12}
\citation{chatterjee2014generalized}
\citation{banerjee14}
\newlabel{corr:single}{{7}{7}{General Error Bound}{theorem.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}}Proof of Theorem \ref  {theo:calcub}}{7}{subsection.4.1}\protected@file@percent }
\newlabel{eq:maxex}{{13}{7}{Proof of Theorem \ref {theo:calcub}}{equation.4.13}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces  {\sc  Dasher}\relax }}{7}{algorithm.1}\protected@file@percent }
\newlabel{alg2}{{1}{7}{\dc \relax }{algorithm.1}{}}
\newlabel{lemm:mainlem}{{8}{7}{Theorem 4 of \cite {banerjee14}}{theorem.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Estimation Algorithm}{7}{section.5}\protected@file@percent }
\newlabel{sec:opt}{{V}{7}{Estimation Algorithm}{section.5}{}}
\citation{banerjee14}
\citation{oyrs15}
\newlabel{def:only}{{4}{8}{Estimation Algorithm}{definition.4}{}}
\newlabel{lemm:hpub}{{9}{8}{Estimation Algorithm}{theorem.9}{}}
\newlabel{gennips}{{14}{8}{Estimation Algorithm}{equation.5.14}{}}
\newlabel{theo:iter}{{10}{8}{Estimation Algorithm}{theorem.10}{}}
\newlabel{eq:singleiter}{{15}{8}{Estimation Algorithm}{equation.5.15}{}}
\newlabel{theo:step}{{11}{9}{Estimation Algorithm}{theorem.11}{}}
\newlabel{corr:show}{{12}{9}{Estimation Algorithm}{theorem.12}{}}
\newlabel{eq:scaled}{{16}{9}{Estimation Algorithm}{equation.5.16}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-A}}Proof Sketch of Theorem \ref  {theo:step}}{9}{subsection.5.1}\protected@file@percent }
\newlabel{proofsketch}{{\unhbox \voidb@x \hbox {V-A}}{9}{Proof Sketch of Theorem \ref {theo:step}}{subsection.5.1}{}}
\bibstyle{IEEEtran}
\bibdata{IEEEabrv,nips18}
\bibcite{candes2010power}{1}
\newlabel{fig syn1a}{{2a}{10}{$n_g = 60$, $\w = 0$\relax }{figure.caption.3}{}}
\newlabel{sub@fig syn1a}{{a}{10}{$n_g = 60$, $\w = 0$\relax }{figure.caption.3}{}}
\newlabel{fig syn1b}{{2b}{10}{$n_g = 60$, $\w _1 \neq 0$\relax }{figure.caption.3}{}}
\newlabel{sub@fig syn1b}{{b}{10}{$n_g = 60$, $\w _1 \neq 0$\relax }{figure.caption.3}{}}
\newlabel{fig syn2a}{{2c}{10}{$n_g = 150$, $\w = 0$\relax }{figure.caption.3}{}}
\newlabel{sub@fig syn2a}{{c}{10}{$n_g = 150$, $\w = 0$\relax }{figure.caption.3}{}}
\newlabel{fig syn2b}{{2d}{10}{$n_g = 150$, $\w = 0$\relax }{figure.caption.3}{}}
\newlabel{sub@fig syn2b}{{d}{10}{$n_g = 150$, $\w = 0$\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \relax \fontsize  {9}{10pt}\selectfont  In (a), (b), and (c) experiments $p = 100$, $G = 10$, $\forall g \in [G]: s_g = 10$, and $s_0 = p$. For (d) $p = 1000$, $G = 100$, $\forall g \in [G]: s_g = 10$, and $s_0 = 100$. (a) Noiseless fast convergence. (b) Noise on the first group does not impact other groups as much. (c) Increasing sample size improves rate of convergence. (d) {\sc  Dasher}\ convergences fast even with a large number of groups $G=100$.\relax }}{10}{figure.caption.3}\protected@file@percent }
\newlabel{fig syn12}{{2}{10}{\small In (a), (b), and (c) experiments $p = 100$, $G = 10$, $\forall g \in [G]: s_g = 10$, and $s_0 = p$. For (d) $p = 1000$, $G = 100$, $\forall g \in [G]: s_g = 10$, and $s_0 = 100$. (a) Noiseless fast convergence. (b) Noise on the first group does not impact other groups as much. (c) Increasing sample size improves rate of convergence. (d) \dc \ convergences fast even with a large number of groups $G=100$.\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {VI}Experiments on Synthetic Data}{10}{section.6}\protected@file@percent }
\newlabel{sec:expds}{{VI}{10}{Experiments on Synthetic Data}{section.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {VII}Conclusion}{10}{section.7}\protected@file@percent }
\bibcite{donoho2006compressed}{2}
\bibcite{friedman2008sparse}{3}
\bibcite{candes2009exact}{4}
\bibcite{candes2006robust}{5}
\bibcite{tibshirani1996regression}{6}
\bibcite{bach2012optimization}{7}
\bibcite{negahban2009unified}{8}
\bibcite{boufounos20081}{9}
\bibcite{plan2017high}{10}
\bibcite{blumensath2009iterative}{11}
\bibcite{jain2013low}{12}
\bibcite{barretina2012cancer}{13}
\bibcite{iorio2016landscape1}{14}
\bibcite{guba16}{15}
\bibcite{mctr13}{16}
\bibcite{Yang2013-pf}{17}
\bibcite{jrsr10}{18}
\bibcite{Zhang2017-rm}{19}
\bibcite{grti16}{20}
\bibcite{asiaee2018high}{21}
\bibcite{asiaeedata}{22}
\bibcite{Chen2015-fj}{23}
\bibcite{domu16}{24}
\bibcite{olvi14}{25}
\bibcite{olvi15}{26}
\bibcite{Kakade2010-st}{27}
\bibcite{negahban2012restricted}{28}
\bibcite{Plan2013-nx}{29}
\bibcite{Plan2016-de}{30}
\bibcite{Yang2016-zd}{31}
\bibcite{Chen2012-fb}{32}
\bibcite{vers12}{33}
\bibcite{vershynin2018high}{34}
\bibcite{banerjee14}{35}
\bibcite{nrwy12}{36}
\bibcite{raskutti10}{37}
\bibcite{mend15}{38}
\bibcite{trop15}{39}
\bibcite{ruzh13}{40}
\bibcite{boucheron13}{41}
\bibcite{bickel2009simultaneous}{42}
\bibcite{candes2007dantzig}{43}
\bibcite{venkat12}{44}
\bibcite{chatterjee2014generalized}{45}
\bibcite{Vaart1996-zl}{46}
\bibcite{Ledoux1991-ix}{47}
\bibcite{oyrs15}{48}
\@writefile{toc}{\contentsline {section}{References}{11}{section*.5}\protected@file@percent }
