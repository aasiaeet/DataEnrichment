\begin{abstract}	
    We consider the problem of multi-task learning in high dimension. In particular, we introduce an estimator and investigate its statistical and computational properties for the problem of multiple connected linear regressions known as Data Sharing. The between-tasks connections are captured by a cross-tasks \emph{common parameter} which gets refined by per-task \emph{individual parameters}. Any convex function, e.g., norm, can characterize the structure of both common and individual parameters.% which is a generalization of the Data Shared LASSO \cite{grti16}.    
	We delineate the sample complexity of our estimator and provide high probability non-asymptotic bound for estimation error of all parameters under a geometric condition. We show that the recovery of the common parameter benefits from \emph{all} of the pooled samples.
	We propose an iterative estimation algorithm with a geometric convergence rate and supplement our theoretical analysis with experiments on synthetic data. 
	Overall, we present a first through statistical and computational analysis of inference in the data sharing model. 
%	We consider the problem of multi-task learning in high dimension. In particular, we propose an estimator and investigate its statistical and computational properties for the problem of multiple connected linear regressions known as Data Sharing. The between-tasks connections is captured by a cross-tasks common parameter which gets refined by per-task individual parameters. Any convex function, e.g., norm, can characterize the structure of both common and individual parameters.% which is a generalization of the Data Shared LASSO \cite{grti16}.	
%	We delineate sample complexity of our estimator and provide high probability non-asymptotic bound for estimation error of all parameters under a geometric condition. 
%	We propose an iterative estimation algorithm with a geometric convergence rate and supplement our theoretical analysis with experiments on synthetic data. 
%	Overall, we present a first through statistical and computational analysis of inference in the data sharing model. 
%	
	%	Interestingly the sample complexity of our estimator translates to conditions on both per-group sample sizes and the total number of samples. 
%High dimensional structured data enriched model describes groups of observations by shared and per-group individual parameters, each with its own structure such as sparsity or group sparsity.
%In this paper, we consider the general form of data enrichment where data comes in a fixed but arbitrary number of groups $G$.  Any convex function, e.g., norms, can characterize the structure of both shared and individual parameters.
%We propose an estimator for high dimensional data enriched model and provide conditions under which it consistently estimates both shared and individual parameters. 
%We also delineate sample complexity of the estimator and present high probability non-asymptotic bound on estimation error of all parameters. 
%Interestingly the sample complexity of our estimator translates to conditions on both per-group sample sizes and the total number of samples. 
%We propose an iterative estimation algorithm with a linear convergence rate and supplement our theoretical analysis with synthetic and real experimental results. 
%In particular, we show the predictive power of data-enriched model along with its interpretable results in anticancer drug sensitivity analysis.    
\end{abstract}